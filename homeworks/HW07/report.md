# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4:

- `S07-hw-dataset-01.csv`
- `S07-hw-dataset-02.csv`
- `S07-hw-dataset-03.csv`

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9)
- Признаки: числовые (`float64`: 8 признаков), `sample_id` (`int64`) — идентификатор
- Пропуски: нет
- "Подлости" датасета: признаки в разных шкалах + шумовые признаки → без масштабирования distance-based методы работают заметно хуже.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4)
- Признаки: числовые (`float64`: 3 признака), `sample_id` (`int64`) — идентификатор  
  Признаки: `x1`, `x2`, `z_noise`
- Пропуски: нет
- "Подлости" датасета: нелинейная структура + выбросы + шумовой признак → KMeans может проигрывать.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000, 5)
- Признаки: числовые (`float64`: 4 признака), `sample_id` (`int64`) — идентификатор  
  Признаки: `x1`, `x2`, `f_corr`, `f_noise`
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности + фоновый шум → сложнее подобрать параметры и получить высокий silhouette.

## 2. Protocol

Использовался "честный" unsupervised-протокол:

- Препроцессинг:
  - `StandardScaler` (масштабирование) для всех признаков.
- Поиск гиперпараметров:
  - KMeans: подбирался `k` в диапазоне 2…15.
  - Второй метод: AgglomerativeClustering, сравнивались варианты `linkage` (`ward`, `average`).
  - Подбор делался на train, финальные метрики считались на test.
- Метрики качества:
  - silhouette_score (выше — лучше),
  - davies_bouldin_score (ниже — лучше),
  - calinski_harabasz_score (выше — лучше).
- Визуализация:
  - PCA(2D) scatter для лучшего решения на каждом датасете,
  - дополнительный график подбора параметров: silhouette vs k для KMeans.

DBSCAN в этой работе не использовался, поэтому доля шума не анализировалась.

## 3. Models

Для каждого датасета сравнивались:

- **KMeans**
  - подбирался `k` (2…15)
  - фиксировали `random_state=42`, `n_init=10`
- **AgglomerativeClustering**
  - выбирали `k` (сравнимый с KMeans)
  - сравнивали `linkage` (ward / average)

## 4. Results

(все финальные метрики по датасетам и моделям сохранены в `artifacts/metrics_summary.json` :contentReference[oaicite:1]{index=1}, а выбор лучшей конфигурации — в `artifacts/best_configs.json` :contentReference[oaicite:2]{index=2})

### 4.1 Dataset A

- Лучший метод и параметры: **KMeans, k=2** :contentReference[oaicite:3]{index=3}
- Метрики (silhouette / DB / CH) на test: :contentReference[oaicite:4]{index=4}
  - silhouette = 0.5179
  - Davies-Bouldin = 0.6870
  - Calinski-Harabasz = 2872.11
- Коротко: после масштабирования KMeans хорошо отделяет кластеры, качество высокое и соответствует структуре данных.

### 4.2 Dataset B

- Лучший метод и параметры: **AgglomerativeClustering, k=2, linkage=average** :contentReference[oaicite:5]{index=5}
- Метрики (silhouette / DB / CH) на test: :contentReference[oaicite:6]{index=6}
  - silhouette = 0.4307
  - Davies-Bouldin = 1.0372
  - Calinski-Harabasz = 103.90
- Коротко: Agglomerative с average linkage лучше справился со сложной структурой данных и выбросами, чем KMeans.

### 4.3 Dataset C

- Лучший метод и параметры: **KMeans, k=3** :contentReference[oaicite:7]{index=7}
- Метрики (silhouette / DB / CH) на test: :contentReference[oaicite:8]{index=8}
  - silhouette = 0.3148
  - Davies-Bouldin = 1.1546
  - Calinski-Harabasz = 1732.39
- Коротко: данные сложнее из-за разной плотности/шума, поэтому silhouette ниже, но KMeans всё равно показал лучшее качество по выбранному критерию.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans хорошо работает, когда кластеры можно отделить “геометрически” и после масштабирования.
- На датасете с нелинейной структурой и выбросами (Dataset B) качество KMeans было заметно хуже, и AgglomerativeClustering оказался лучше по silhouette.
- В целом сильнее всего на результат влияло масштабирование, а также сложность формы кластеров и наличие выбросов/шума.

### 5.2 Устойчивость (обязательно для одного датасета)

Проверка устойчивости выполнена на Dataset A для KMeans:

- сделано 5 запусков с разными `random_state`
- оценивалась похожесть кластеризаций через ARI (Adjusted Rand Index)

Результат:
- mean ARI = 1.0, std = 0.0 (все запуски дали одинаковые разбиения)

Вывод:
- кластеризация полностью устойчива, т.к. структура кластеров в данных выражена чётко.

### 5.3 Интерпретация кластеров

Кластеры интерпретировались через PCA(2D) scatter (визуальная проверка структуры):

- на Dataset A видны 2 хорошо отделимые группы;
- на Dataset B структура менее “шарообразная”, поэтому KMeans работает хуже;
- на Dataset C присутствует шум и разная плотность, что отражается на снижении silhouette.

## 6. Conclusion

- Distance-based кластеризация требует масштабирования признаков, иначе метрики ухудшаются.
- KMeans хорошо подходит для “шарообразных” кластеров, но плохо переносит выбросы и нелинейные формы.
- AgglomerativeClustering может выигрывать на более сложной структуре данных за счёт другой логики объединения кластеров.
- Внутренние метрики (silhouette / DB / CH) полезны для выбора конфигурации без истинных меток, но их нужно смотреть вместе.
- PCA(2D) помогает визуально понять структуру кластеров и сопоставить её с метриками.
- "Честный" протокол (подбор на train, оценка на test) делает unsupervised-эксперимент более корректным и воспроизводимым.