# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-04.csv`
- Размер: (25000, 62)
- Целевая переменная: `target` - бинарная классификация (0/1), сильный дисбаланс классов  
  Доли классов: 0 - 0.9508, 1 - 0.0492
- Признаки: в основном числовые признаки `f01...fXX`. Признак `id` (если присутствует) не использовался как фича.

## 2. Protocol

- Разбиение: train/test = 75% / 25%, `random_state=42`, `stratify=y`.
- Подбор: гиперпараметры подбирались только на train через CV:  
  `StratifiedKFold(n_splits=5, shuffle=True, random_state=42)`.
- Оптимизация: подбор моделей выполнялся по метрике **ROC-AUC** (`GridSearchCV(scoring="roc_auc")`).
- Метрики:
  - **accuracy** - базовая метрика, но при дисбалансе может быть неинформативной;
  - **F1-score** - полезна при дисбалансе, так как учитывает precision и recall;
  - **ROC-AUC** - основная метрика для бинарной классификации, показывает качество ранжирования вероятностей;
  - дополнительно **Average Precision (PR-AUC)** - особенно важна для fraud-like задач (dataset-04), где важно качество на редком классе.

Test использовался один раз - только для финальной оценки.

## 3. Models

Сравнивались модели:

- **DummyClassifier(strategy="most_frequent")** - baseline, всегда предсказывает самый частый класс.
- **LogisticRegression** - baseline, использовался `Pipeline(StandardScaler + LogisticRegression)`.
- **DecisionTreeClassifier** - одиночное дерево решений, контролировали сложность через:
  - `max_depth`
  - `min_samples_leaf`
- **RandomForestClassifier** - bagging деревьев + случайность по признакам:
  - `n_estimators`
  - `max_depth`
  - `min_samples_leaf`
  - `max_features`
  Использовался `class_weight="balanced_subsample"`.
- **GradientBoostingClassifier** - boosting:
  - `n_estimators`
  - `learning_rate`
  - `max_depth`

Подбор гиперпараметров выполнялся только на train через CV.

## 4. Results

Финальные метрики на test (accuracy / F1 / ROC-AUC / AP):

- Dummy_most_frequent:
  - accuracy = 0.9509
  - F1 = 0.0000
  - ROC-AUC = 0.5000
  - AP = 0.0491

- LogReg:
  - accuracy = 0.7792
  - F1 = 0.2573
  - ROC-AUC = 0.8419
  - AP = 0.4570

- DecisionTree:
  - accuracy = 0.8744
  - F1 = 0.3592
  - ROC-AUC = 0.8309
  - AP = 0.4381

- RandomForest:
  - accuracy = 0.9686
  - F1 = 0.5311
  - ROC-AUC = 0.9014
  - AP = 0.7798

- GradientBoosting:
  - accuracy = 0.9746
  - F1 = 0.6851
  - ROC-AUC = 0.8922
  - AP = 0.7033

Победитель по ROC-AUC:
- **RandomForest** (ROC-AUC = 0.9014, AP = 0.7798)

Краткое объяснение:
- DummyClassifier показывает нижнюю границу качества и на дисбалансном датасете выдаёт высокую accuracy, но F1=0 (вообще не находит редкий класс).
- LogisticRegression как baseline даёт неплохой ROC-AUC, но хуже справляется с нелинейностями.
- Одиночное дерево даёт качество выше baseline, но менее устойчиво и хуже, чем ансамбли.
- RandomForest показал лучший баланс качества (ROC-AUC и AP), так как уменьшает variance и устойчивее деревьев.
- GradientBoosting показал хорошую F1, но по ROC-AUC уступил RandomForest.

## 5. Analysis

- Устойчивость:
  При смене `random_state` метрики могут немного меняться, что ожидаемо на дисбалансных данных.
  В целом ансамбли (RandomForest / Boosting) показывают более устойчивые результаты, чем одиночное дерево.

- Ошибки:
  Confusion matrix для лучшей модели лежит в `artifacts/figures/cm_RandomForest.png`.
  На дисбалансном датасете высокая accuracy не гарантирует хорошее качество на редком классе, поэтому дополнительно анализировались ROC и PR кривые.

- Интерпретация:
  Для лучшей модели (RandomForest) была посчитана permutation importance (top-15).
  Наиболее важные признаки по permutation importance:
  - `f58` (importance_mean ≈ 0.0103)
  - `f53` (≈ 0.0097)
  - `f13` (≈ 0.0076)
  - `f47` (≈ 0.0068)
  - `f25` (≈ 0.0054)

  Это означает, что качество модели сильнее всего определяется небольшим набором признаков, а остальные дают меньший вклад.

## 6. Conclusion

- Дерево решений склонно к переобучению, поэтому важно ограничивать его сложность (`max_depth`, `min_samples_leaf`).
- RandomForest снижает variance по сравнению с одиночным деревом и чаще даёт более устойчивое качество.
- Boosting может давать сильные результаты, так как последовательно исправляет ошибки предыдущих моделей.
- При сильном дисбалансе accuracy может быть обманчивой метрикой, поэтому важны ROC-AUC и PR-AUC.
- Честный ML-протокол (train/test split + CV только на train) предотвращает утечку информации и завышенные результаты.
- Сохранение артефактов (метрики, параметры, модель, графики) делает эксперимент воспроизводимым и удобным для проверки.
